{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 0 - ConvNet no MNIST-[HP].ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "text",
      "language": "python",
      "name": "text"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bsguedes/machine-learning/blob/master/Aula_0_ConvNet_no_MNIST_%5BHP%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4qQnZ-mLpXjH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xGR0SSZMpXjL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Atenção: Rode esta linha apenas se estiver usando o Google Colab"
      ]
    },
    {
      "metadata": {
        "id": "hygGGH3upXjL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qDNLT-xcpXjO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchvision\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WIEw5kzOpXjR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### O código da célula abaixo contém funções para efetuar a carga dos dados, treinamento teste dos modelos"
      ]
    },
    {
      "metadata": {
        "id": "XA24z6nqpXjS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_loaders(batch_size):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=datasets.MNIST(\n",
        "            root='../data', \n",
        "            train=True, \n",
        "            download=True,\n",
        "            transform=transform,\n",
        "        ),\n",
        "        batch_size=batch_size, \n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        dataset=datasets.MNIST(\n",
        "            root='../data', \n",
        "            train=False, \n",
        "            download=True,\n",
        "            transform=transform,\n",
        "        ),\n",
        "        batch_size=batch_size, \n",
        "        shuffle=True\n",
        "    )\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def train_epoch(\n",
        "        model, \n",
        "        device, \n",
        "        train_loader, \n",
        "        optimizer, \n",
        "        criterion, \n",
        "        epoch, \n",
        "        log_interval\n",
        "    ):\n",
        "    model.train()\n",
        "    history = []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(\n",
        "        model, \n",
        "        device, \n",
        "        criterion, \n",
        "        test_loader\n",
        "    ):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item() # sum up batch loss\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        accuracy))\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def train(\n",
        "        model,\n",
        "        train_loader,\n",
        "        test_loader,\n",
        "        device,\n",
        "        lr,\n",
        "        nb_epochs=3,\n",
        "        log_interval=100,\n",
        "    ):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    for epoch in range(1, nb_epochs + 1):\n",
        "        print('\\n* * * Training * * *')\n",
        "        train_epoch(\n",
        "            model=model, \n",
        "            device=device, \n",
        "            train_loader=train_loader, \n",
        "            optimizer=optimizer, \n",
        "            criterion=criterion, \n",
        "            epoch=epoch, \n",
        "            log_interval=log_interval\n",
        "        )\n",
        "        print('\\n* * * Evaluating * * *')\n",
        "        acc = test(model, device, criterion, test_loader)        \n",
        "    \n",
        "    return acc\n",
        "\n",
        "def check_input(model, device):\n",
        "    dummy_data = torch.zeros(5, 1, 28, 28).to(device)\n",
        "    dummy_pred = model(dummy_data)        \n",
        "    assert dummy_pred.shape == (5, 10), '\\nOutput expected: (batch_size, 10) \\nOutput found   : {}'.format(dummy_pred.shape)\n",
        "    print('Passed')\n",
        "    return dummy_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PyjIYZwdpXjV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Hyper-parâmetros que você pode definir"
      ]
    },
    {
      "metadata": {
        "id": "EyJ4PQJBpXjW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "device_name = 'cpu'\n",
        "nb_epochs = 3\n",
        "log_interval = 500\n",
        "lr = 1e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MGJr2tNlpXja",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(device_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5gzXOeSpXje",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conferência dos dados"
      ]
    },
    {
      "metadata": {
        "id": "r7V5sKUMpXjf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = get_loaders(batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JLkW_IYbpXji",
        "colab_type": "code",
        "outputId": "5a4a34bc-e51f-4a29-f64e-0b05cb993df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\n",
        "    'Train size: ', \n",
        "    train_loader.dataset.train_data.shape, \n",
        "    train_loader.dataset.train_labels.shape\n",
        ")\n",
        "print(\n",
        "    'Test size : ', \n",
        "    test_loader.dataset.test_data.shape, \n",
        "    test_loader.dataset.test_labels.shape\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train size: ', torch.Size([60000, 28, 28]), torch.Size([60000]))\n",
            "('Test size : ', torch.Size([10000, 28, 28]), torch.Size([10000]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aMD5S0xkpXjn",
        "colab_type": "code",
        "outputId": "c191c61b-2e8c-49a7-c872-2d23ff93cd55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 5)\n",
        "for i, ax in enumerate(axs):\n",
        "    ax.imshow(train_loader.dataset.train_data[i], cmap='gray')\n",
        "    ax.set_title(train_loader.dataset.train_labels[i].item())\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABXCAYAAACnZJZlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "08uanEbGpXjo",
        "colab_type": "code",
        "outputId": "7691da80-81ea-4a3c-c08b-7876777f553d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "instance = next(iter(train_loader))\n",
        "print('Instance Example: ', instance[0].shape, instance[1].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Instance Example: ', torch.Size([16, 1, 28, 28]), torch.Size([16]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hUgQZHtxpXjq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Seu trabalho começa aqui:"
      ]
    },
    {
      "metadata": {
        "id": "v3SMH2DapXjr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Implemente aqui sua primeira rede convolucional  \n",
        "\n",
        "Sua ConvNet deve ser capaz de classificar as imagens do MNIST. Lembre-se que as imagens do MNIST tem apenas 1 canal, isto é, elas são em escala de cinza (e não RBG!)."
      ]
    },
    {
      "metadata": {
        "id": "zNb6eZgkpXjs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.fc = nn.Linear(in_features=3136, out_features=10)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.shape[0], 64*7*7) # Ou x = x.view(x.shape[0], -1)\n",
        "        out = self.fc(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5L3hksa2pXju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 Verifique se a saída do seu modelo está correta"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "dtSmcRFRpXjx",
        "colab_type": "code",
        "outputId": "8a266921-6a81-4565-d0ad-cb8189084ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = ConvNet().to(device)\n",
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZvFFNCZ3pXjz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 Treine seu modelo por uma ou mais épocas. \n",
        "\n",
        "Você deve conseguir ~99% de acurácia na terceira época. "
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "NQ6b-mXOpXj0",
        "colab_type": "code",
        "outputId": "9758efab-75a3-4ccb-9b61-2b34c6657c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.278495\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.040009\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.253451\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.034898\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.062593\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.021112\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.034876\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.004264\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0029, Accuracy: 9856/10000 (98.56%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.002109\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.001524\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.021909\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.017433\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.025212\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.003113\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.118879\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.016065\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0023, Accuracy: 9879/10000 (98.79%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.031539\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.000110\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.000037\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.050523\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.002379\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.021491\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.000778\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.006810\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0022, Accuracy: 9885/10000 (98.85%)\n",
            "\n",
            "Final acc: 98.85%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "40qZnvBupXj1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Atualize sua rede convolucional para usar o container nn.Sequential()\n",
        "\n",
        "A arquitetura da rede pode ser exatamente igual à rede anterior, porém, agora use o nn.Sequential para criar as camadas."
      ]
    },
    {
      "metadata": {
        "id": "wkfP4AHdsz5d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bdP0ElDxpXj2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvNetSeq(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNetSeq, self).__init__()\n",
        "        conv_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        pool = nn.MaxPool2d(kernel_size=2)\n",
        "        relu = nn.ReLU(inplace=True)        \n",
        "        conv_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        f = Flatten()\n",
        "        fc = nn.Linear(in_features=3136, out_features=10)\n",
        "        self.conv = nn.Sequential(*[conv_1, relu, pool, conv_2, relu, pool, f, fc])\n",
        "        \n",
        "    def forward(self, x):        \n",
        "        x = self.conv(x)        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "2XIk7D5rpXj3",
        "colab_type": "code",
        "outputId": "9824b090-f55c-4750-d6ed-7929148e73d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = ConvNetSeq().to(device)\n",
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MSS6Y27bpXj5",
        "colab_type": "code",
        "outputId": "9d4d11e8-4fb4-4d26-9a98-dd13d5660c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.251601\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.041242\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.270237\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.019643\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.001349\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.050446\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.007996\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.104473\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0032, Accuracy: 9842/10000 (98.42%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.124676\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.006518\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.002075\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.007109\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.002999\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.158949\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.008097\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.117409\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0023, Accuracy: 9871/10000 (98.71%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.009814\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.007589\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.092994\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.000512\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.000165\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.001076\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.000603\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.002454\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0019, Accuracy: 9898/10000 (98.98%)\n",
            "\n",
            "Final acc: 98.98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BEhbkgaMpXj6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Crie uma nova rede substituindo as camadas de convolução da sua rede anterior por blocos Inception.  \n",
        "\n",
        "Detalhes:\n",
        "\n",
        "1. Crie um novo módulo (classe que herda do nn.Module) chamado de InceptionModule. \n",
        "2. Nesse módulo você deverá criar camadas convolucionais com filtros 1x1, 3x3 e 5x5 paralelamente. No final, concatene o resultado, e aplique mais uma convolução 1x1 para reduzir a dimensionalidade ao tamanho original. \n",
        "2. Atualize sua rede convolucional substituindo as camadas de convolução pelo seu bloco Inception. \n",
        "3. Treine o modelo e reporte a acurácia. "
      ]
    },
    {
      "metadata": {
        "id": "XPbhRK3SpXj6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class InceptionModule(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(InceptionModule, self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, padding=0)\n",
        "        self.conv_3 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1)\n",
        "        self.conv_5 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=5, padding=2)\n",
        "        \n",
        "        self.conv_out = nn.Conv2d(in_channels=3*out_channels, out_channels=out_channels, kernel_size=1, padding=0)\n",
        "\n",
        "    def forward(self, x):        \n",
        "        a = self.conv_1(x)\n",
        "        b = self.conv_3(x)\n",
        "        c = self.conv_5(x)\n",
        "        #print(a.shape)\n",
        "        #print(b.shape)\n",
        "        #print(c.shape)\n",
        "        out = torch.cat((a, b, c), 1)\n",
        "        #print(out.shape)\n",
        "        out = self.conv_out(out)\n",
        "        #print(out.shape)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nY0UdH6lpXj9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class InceptionNet(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(InceptionNet, self).__init__()            \n",
        "        conv_1 = InceptionModule(1, 32)\n",
        "        pool = nn.MaxPool2d(kernel_size=2)\n",
        "        relu = nn.ReLU(inplace=True)        \n",
        "        conv_2 = InceptionModule(32, 64)\n",
        "        f = Flatten()\n",
        "        fc = nn.Linear(in_features=3136, out_features=10)\n",
        "        self.conv = nn.Sequential(*[conv_1, relu, pool, conv_2, relu, pool, f, fc])\n",
        "        \n",
        "    def forward(self, x):        \n",
        "        x = self.conv(x)        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QD_GGDRlpXj-",
        "colab_type": "code",
        "outputId": "4116dd4a-1ac1-4ae0-d60c-c828b04ea18c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = InceptionNet().to(device)\n",
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-GlsAawXpXkB",
        "colab_type": "code",
        "outputId": "f28ebc19-c74a-4611-98cb-c9ae368e3403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.322847\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.010897\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.000443\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.059627\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.006965\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.055700\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.002552\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.004367\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0022, Accuracy: 9879/10000 (98.79%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.006610\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.018144\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.109742\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.000026\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.319504\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.003000\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.012796\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.013999\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0025, Accuracy: 9869/10000 (98.69%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.006820\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.025254\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.000422\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.000265\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.000230\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.011441\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.055004\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.008247\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0027, Accuracy: 9862/10000 (98.62%)\n",
            "\n",
            "Final acc: 98.62%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}