{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 3 - Classificação de Vídeos-[HP].ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "vse27",
      "language": "python",
      "name": "vse27"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bsguedes/machine-learning/blob/master/Aula_3_Classifica%C3%A7%C3%A3o_de_V%C3%ADdeos_%5BHP%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Ia8WiFebjiIk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7x8uHOSrjiIo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Atenção: Rode esta linha apenas se estiver usando o Google Colab"
      ]
    },
    {
      "metadata": {
        "id": "m6Z39u8RjiIp",
        "colab_type": "code",
        "outputId": "93cd7b74-3f20-4e0d-c454-78f8e344c0fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mfastai 0.7.0 has requirement torch<0.4, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p7PfgPiqjiIr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchvision\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xGHwLMMjiIt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### O código da célula abaixo contém funções para efetuar a carga dos dados, treinamento teste dos modelos"
      ]
    },
    {
      "metadata": {
        "id": "DMAA8jXTjiIt",
        "colab_type": "code",
        "outputId": "89f92f8a-64fa-4795-a1b7-15f9be0c4c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "# Download do dataset\n",
        "import os \n",
        "if not os.path.exists('videodata.zip'):\n",
        "    !wget https://s3-us-west-2.amazonaws.com/wehrmann/videodata.zip\n",
        "    !unzip videodata.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-29 21:58:06--  https://s3-us-west-2.amazonaws.com/wehrmann/videodata.zip\n",
            "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.249.112\n",
            "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.249.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21784221 (21M) [application/zip]\n",
            "Saving to: ‘videodata.zip’\n",
            "\n",
            "videodata.zip       100%[===================>]  20.77M  18.1MB/s    in 1.1s    \n",
            "\n",
            "2019-01-29 21:58:07 (18.1 MB/s) - ‘videodata.zip’ saved [21784221/21784221]\n",
            "\n",
            "Archive:  videodata.zip\n",
            "  inflating: test_videos.npy         \n",
            "  inflating: test_labels.npy         \n",
            "  inflating: train_labels.npy        \n",
            "  inflating: train_videos.npy        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XWcN8f1jjiIw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class VideoLoader(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, path='./', data_split='train',):\n",
        "        super(VideoLoader, self).__init__()\n",
        "        self.data = np.load('{}/{}_videos.npy'.format(path, data_split))\n",
        "        self.labels = np.load('{}/{}_labels.npy'.format(path, data_split))\n",
        "        \n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "                \n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        video = self.data[index].transpose([0, 2, 3, 1])\n",
        "        x = [self.transform(frame) for frame in video]\n",
        "        x = torch.stack(x, 0)\n",
        "        \n",
        "        label = self.labels[index]\n",
        "        return x, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "            \n",
        "            \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xmxb2nivjiIy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_loaders(batch_size):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=VideoLoader(data_split='train'),\n",
        "        batch_size=batch_size, \n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        dataset=VideoLoader(data_split='test'),\n",
        "        batch_size=batch_size, \n",
        "        shuffle=True\n",
        "    )\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def train_epoch(\n",
        "        model, \n",
        "        device, \n",
        "        train_loader, \n",
        "        optimizer, \n",
        "        criterion, \n",
        "        epoch, \n",
        "        log_interval\n",
        "    ):\n",
        "    model.train()\n",
        "    history = []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(\n",
        "        model, \n",
        "        device, \n",
        "        criterion, \n",
        "        test_loader\n",
        "    ):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item() # sum up batch loss\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        accuracy))\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def train(\n",
        "        model,\n",
        "        train_loader,\n",
        "        test_loader,\n",
        "        device,\n",
        "        lr,\n",
        "        nb_epochs=3,\n",
        "        log_interval=100,\n",
        "    ):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    for epoch in range(1, nb_epochs + 1):\n",
        "        print('\\n* * * Training * * *')\n",
        "        train_epoch(\n",
        "            model=model, \n",
        "            device=device, \n",
        "            train_loader=train_loader, \n",
        "            optimizer=optimizer, \n",
        "            criterion=criterion, \n",
        "            epoch=epoch, \n",
        "            log_interval=log_interval\n",
        "        )\n",
        "        print('\\n* * * Evaluating * * *')\n",
        "        acc = test(model, device, criterion, test_loader)        \n",
        "    \n",
        "    return acc\n",
        "\n",
        "def check_input(model, device):\n",
        "    dummy_data = torch.zeros(5, 3, 1, 28, 28).to(device)\n",
        "    dummy_pred = model(dummy_data)        \n",
        "    assert dummy_pred.shape == (5, 2), '\\nOutput expected: (batch_size, 10) \\nOutput found   : {}'.format(dummy_pred.shape)\n",
        "    print('Passed')\n",
        "    return dummy_pred\n",
        "\n",
        "def plot_instances(videos, labels, n_instances=5, n_frames=3):\n",
        "    fig, axes = plt.subplots(n_instances, n_frames)\n",
        "    for i, axs in enumerate(axes):\n",
        "        for j, ax in enumerate(axs):\n",
        "            ax.imshow(videos[i,j].squeeze(), cmap='gray')            \n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "        ax.text(35, 15, 'Label: {} - {}'.format(labels[i], label_dict[labels[i]]), fontsize=14)\n",
        "\n",
        "label_dict = ['Decrescente', 'Crescente']        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FLJKKuJrjiI0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Hyper-parâmetros que você pode definir"
      ]
    },
    {
      "metadata": {
        "id": "pme2nz2GjiI1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "device_name = 'cpu'\n",
        "nb_epochs = 3\n",
        "log_interval = 500\n",
        "lr = 2e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YBpzS_YIjiI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(device_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQYqMkKhjiI6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conferência dos dados"
      ]
    },
    {
      "metadata": {
        "id": "lJ686kYqjiI6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = get_loaders(batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dz67J2cqjiI8",
        "colab_type": "code",
        "outputId": "9ada5480-ebc2-4bd0-de77-3f0a919db3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\n",
        "    'Train size: ', \n",
        "    train_loader.dataset.data.shape, \n",
        "    train_loader.dataset.labels.shape\n",
        ")\n",
        "print(\n",
        "    'Test size : ', \n",
        "    test_loader.dataset.data.shape, \n",
        "    test_loader.dataset.labels.shape\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train size: ', (40000, 3, 1, 28, 28), (40000,))\n",
            "('Test size : ', (4000, 3, 1, 28, 28), (4000,))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sSDvqOtqjiI9",
        "colab_type": "code",
        "outputId": "27873554-5511-454f-b312-80ff01a079de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "videos, labels = next(iter(train_loader))\n",
        "print('Instance Example: ', videos.shape, labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Instance Example: ', torch.Size([16, 3, 1, 28, 28]), torch.Size([16]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bkdWhYlZjiJA",
        "colab_type": "code",
        "outputId": "c089fe49-5488-418e-feff-435198183c95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "cell_type": "code",
      "source": [
        "plot_instances(videos, labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAADnCAYAAACdbhioAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyQ0A4B0mNwCAd5jcAADeYXIDAHjnAwMh7KmYxjgLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 15 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bmWrPeDtjiJC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Seu trabalho começa aqui:"
      ]
    },
    {
      "metadata": {
        "id": "XeGuFU4njiJC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Crie uma rede neural, usando `nn.LSTM()` ou `nn.GRU()` para processar a dimensão temporal. \n",
        "\n",
        "\n",
        "* Utilize a rede DigitsConvNet para processar cada um dos frames. \n",
        "* Utilize uma rede recorrente da sua escolha para processar a dimensão temporal. "
      ]
    },
    {
      "metadata": {
        "id": "ErXKeR_0jiJE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class DigitsConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DigitsConvNet, self).__init__()\n",
        "        conv_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        pool = nn.MaxPool2d(kernel_size=2)\n",
        "        relu = nn.ReLU(inplace=True)        \n",
        "        conv_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        f = Flatten()        \n",
        "        self.conv = nn.Sequential(*[conv_1, relu, pool, conv_2, relu, pool, f])\n",
        "        \n",
        "    def forward(self, x):        \n",
        "        x = self.conv(x)        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nWsN4IrJjiJF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class VideoLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VideoLSTM, self).__init__()                \n",
        "        self.lstm = nn.LSTM(input_size=3136, hidden_size=64,batch_first=True)\n",
        "        self.fc = nn.Linear(64,2)\n",
        "        self.digitscnn = DigitsConvNet()\n",
        "        \n",
        "    def forward(self, x):        \n",
        "        batch, time_steps, channels, h, w = x.shape\n",
        "        x_flat = x.view(batch*time_steps, channels, h, w)\n",
        "        features = self.digitscnn(x_flat)\n",
        "        features = features.view(batch, time_steps, -1)        \n",
        "        out, (h, c) = self.lstm(features)\n",
        "        out = out[:,-1,:]\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "U-HGFRArjiJH",
        "colab_type": "code",
        "outputId": "de44754d-83ce-4db3-8ac8-44564e1577f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "model = VideoLSTM().to(device)\n",
        "print(model)\n",
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VideoLSTM(\n",
            "  (lstm): LSTM(3136, 64, batch_first=True)\n",
            "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
            "  (digitscnn): DigitsConvNet(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace)\n",
            "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): ReLU(inplace)\n",
            "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (6): Flatten()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GxH44HcojiJJ",
        "colab_type": "code",
        "outputId": "2a4ca14e-aa53-4e42-e41d-9d725044d02a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1081
        }
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/40000 (0%)]\tLoss: 0.686834\n",
            "Train Epoch: 1 [8000/40000 (20%)]\tLoss: 0.180126\n",
            "Train Epoch: 1 [16000/40000 (40%)]\tLoss: 0.088345\n",
            "Train Epoch: 1 [24000/40000 (60%)]\tLoss: 0.022944\n",
            "Train Epoch: 1 [32000/40000 (80%)]\tLoss: 0.019196\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0015, Accuracy: 3982/4000 (99.55%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 2 [0/40000 (0%)]\tLoss: 0.008036\n",
            "Train Epoch: 2 [8000/40000 (20%)]\tLoss: 0.001066\n",
            "Train Epoch: 2 [16000/40000 (40%)]\tLoss: 0.010198\n",
            "Train Epoch: 2 [24000/40000 (60%)]\tLoss: 0.008732\n",
            "Train Epoch: 2 [32000/40000 (80%)]\tLoss: 0.002594\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0006, Accuracy: 3991/4000 (99.78%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 3 [0/40000 (0%)]\tLoss: 0.000374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f93f64f9fa19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Final acc: {:.2f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-8215eb87eebf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n* * * Evaluating * * *'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-8215eb87eebf>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, device, train_loader, optimizer, criterion, epoch, log_interval)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "QItWWXLojiJM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Atualize sua rede de classificação de vídeos usando uma Rede Recorrente Bidirecional (`nn.LSTM(bidirectional=True)`, `nn.GRU(bidirectional=True`))"
      ]
    },
    {
      "metadata": {
        "id": "-N-gS7xbjiJN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BiRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BiRNN, self).__init__()                \n",
        "        self.lstm = nn.LSTM(input_size=3136, hidden_size=32, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(64,2)\n",
        "        self.digitscnn = DigitsConvNet()\n",
        "        \n",
        "    def forward(self, x):        \n",
        "        batch, time_steps, channels, h, w = x.shape\n",
        "        x_flat = x.view(batch*time_steps, channels, h, w)\n",
        "        features = self.digitscnn(x_flat)\n",
        "        features = features.view(batch, time_steps, -1)        \n",
        "        #print(features.shape)\n",
        "        out, (h, c) = self.lstm(features)\n",
        "        #print(out.shape)\n",
        "        out = out[:,-1,:]\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a03mBJIAjiJQ",
        "colab_type": "code",
        "outputId": "f4a0d529-4d70-4bbb-e4d5-f283592968f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = BiRNN().to(device)\n",
        "#print(model)\n",
        "\n",
        "pred = model(torch.zeros(5, 3, 1, 28, 28))\n",
        "print(pred.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dp-qIbbxjiJT",
        "colab_type": "code",
        "outputId": "ac9a2eb9-bc9b-4a62-a233-48b0cb63c455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 3136])\n",
            "torch.Size([5, 3, 64])\n",
            "Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZA0LH5bljiJV",
        "colab_type": "code",
        "outputId": "77939448-7af7-47cf-dc1e-bc42bfff603d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/40000 (0%)]\tLoss: 0.692703\n",
            "Train Epoch: 1 [8000/40000 (20%)]\tLoss: 0.332202\n",
            "Train Epoch: 1 [16000/40000 (40%)]\tLoss: 0.296921\n",
            "Train Epoch: 1 [24000/40000 (60%)]\tLoss: 0.216287\n",
            "Train Epoch: 1 [32000/40000 (80%)]\tLoss: 0.065810\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0025, Accuracy: 3965/4000 (99.12%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 2 [0/40000 (0%)]\tLoss: 0.138133\n",
            "Train Epoch: 2 [8000/40000 (20%)]\tLoss: 0.012732\n",
            "Train Epoch: 2 [16000/40000 (40%)]\tLoss: 0.011181\n",
            "Train Epoch: 2 [24000/40000 (60%)]\tLoss: 0.012165\n",
            "Train Epoch: 2 [32000/40000 (80%)]\tLoss: 0.001751\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0011, Accuracy: 3983/4000 (99.58%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 3 [0/40000 (0%)]\tLoss: 0.012893\n",
            "Train Epoch: 3 [8000/40000 (20%)]\tLoss: 0.001240\n",
            "Train Epoch: 3 [16000/40000 (40%)]\tLoss: 0.000688\n",
            "Train Epoch: 3 [24000/40000 (60%)]\tLoss: 0.001538\n",
            "Train Epoch: 3 [32000/40000 (80%)]\tLoss: 0.017809\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0004, Accuracy: 3994/4000 (99.85%)\n",
            "\n",
            "Final acc: 99.85%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "etUbuMYAjiJY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Implemente uma rede neural para classificação de vídeos usando um *global average pooling* para processar a dimensão temporal\n",
        "\n",
        "**OBS: Treine esta rede por apenas 1 época!**\n",
        "\n",
        "Sua rede deve conter uma rede convolucional para processar cada *frame* do vídeo. O processamnto da dimensão temporal deverá ser feito através de um *global average pooling*. "
      ]
    },
    {
      "metadata": {
        "id": "lm5rmEIajiJZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class GlobalPoolNet(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(GlobalPoolNet, self).__init__()                \n",
        "      self.avg_pool = nn.AvgPool2d(kernel_size=(3, 1))\n",
        "      self.fc = nn.Linear(3136,2)\n",
        "      self.digitscnn = DigitsConvNet()\n",
        "        \n",
        "    def forward(self, x):        \n",
        "        batch, time_steps, channels, h, w = x.shape\n",
        "        x_flat = x.view(batch*time_steps, channels, h, w)\n",
        "        features = self.digitscnn(x_flat)\n",
        "        features = features.view(batch, time_steps, -1)      \n",
        "        # print(features.shape)        \n",
        "        out = self.avg_pool(features)\n",
        "        # print(out.shape)\n",
        "        out = out[:,-1,:]\n",
        "        out = self.fc(out)\n",
        "        return out        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iz0a-UT3jiJb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.1 Verifique se a saída do seu modelo está correta"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "dMMG3BecjiJb",
        "colab_type": "code",
        "outputId": "6d7b186d-afc9-4239-82bc-b15dc42bfd25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "model = GlobalPoolNet().to(device)\n",
        "print(model)\n",
        "\n",
        "pred = model(torch.zeros(5, 3, 1, 28, 28).to(device))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GlobalPoolNet(\n",
            "  (avg_pool): AvgPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0)\n",
            "  (fc): Linear(in_features=3136, out_features=2, bias=True)\n",
            "  (digitscnn): DigitsConvNet(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace)\n",
            "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): ReLU(inplace)\n",
            "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (6): Flatten()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5vQL1jlIjiJd",
        "colab_type": "code",
        "outputId": "5d3eaba3-8e8b-41c3-f2a2-d25d0e833f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 3136])\n",
            "torch.Size([5, 1, 3136])\n",
            "Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pr4djN2VjiJf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2 Treine seu modelo por uma (1) época"
      ]
    },
    {
      "metadata": {
        "id": "gdbh-R1IjiJf",
        "colab_type": "code",
        "outputId": "3ffde2d4-8492-4690-cdcf-1c68c0cdea6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, 1, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/40000 (0%)]\tLoss: 0.673952\n",
            "Train Epoch: 1 [8000/40000 (20%)]\tLoss: 0.705662\n",
            "Train Epoch: 1 [16000/40000 (40%)]\tLoss: 0.689061\n",
            "Train Epoch: 1 [24000/40000 (60%)]\tLoss: 0.686465\n",
            "Train Epoch: 1 [32000/40000 (80%)]\tLoss: 0.692346\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0433, Accuracy: 2025/4000 (50.62%)\n",
            "\n",
            "Final acc: 50.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "57RyJ74tjiJl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Implemente o processamento da dimensão temporal utilizando uma camada de convolução \n"
      ]
    },
    {
      "metadata": {
        "id": "a5CatQRpjiJl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class VideoConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VideoConvNet, self).__init__()            \n",
        "        self.conv = nn.Conv1d(3,32,3)\n",
        "        self.fc = nn.Linear(3134, 2)\n",
        "        self.digitscnn = DigitsConvNet()\n",
        "        \n",
        "    def forward(self, x):        \n",
        "        batch, time_steps, channels, h, w = x.shape\n",
        "        x_flat = x.view(batch*time_steps, channels, h, w)\n",
        "        features = self.digitscnn(x_flat)\n",
        "        features = features.view(batch, time_steps, -1)      \n",
        "        # print(features.shape)        \n",
        "        out = self.conv(features)\n",
        "        # print(out.shape)\n",
        "        out = out[:,-1,:]\n",
        "        out = self.fc(out)\n",
        "        return out  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p9GtpyJxjiJn",
        "colab_type": "code",
        "outputId": "ddfec14b-8bf4-47b2-c6e3-d9f9302c47f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "model = VideoConvNet().to(device)\n",
        "print(model)\n",
        "\n",
        "pred = model(torch.zeros(5, 3, 1, 28, 28))\n",
        "print(pred.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VideoConvNet(\n",
            "  (conv): Conv1d(3, 32, kernel_size=(3,), stride=(1,))\n",
            "  (fc): Linear(in_features=3134, out_features=2, bias=True)\n",
            "  (digitscnn): DigitsConvNet(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace)\n",
            "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): ReLU(inplace)\n",
            "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (6): Flatten()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "torch.Size([5, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kx8P-jMrjiJq",
        "colab_type": "code",
        "outputId": "c8acaa25-082f-4e32-d0cb-5cc5c9fb369e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 3136])\n",
            "torch.Size([5, 32, 3134])\n",
            "Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dcnrC6BFjiJs",
        "colab_type": "code",
        "outputId": "d3055ace-b048-44f7-95f6-e7c56b92e395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/40000 (0%)]\tLoss: 0.703469\n",
            "Train Epoch: 1 [8000/40000 (20%)]\tLoss: 0.527795\n",
            "Train Epoch: 1 [16000/40000 (40%)]\tLoss: 0.305585\n",
            "Train Epoch: 1 [24000/40000 (60%)]\tLoss: 0.272895\n",
            "Train Epoch: 1 [32000/40000 (80%)]\tLoss: 0.206722\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0164, Accuracy: 3590/4000 (89.75%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 2 [0/40000 (0%)]\tLoss: 0.120468\n",
            "Train Epoch: 2 [8000/40000 (20%)]\tLoss: 0.093552\n",
            "Train Epoch: 2 [16000/40000 (40%)]\tLoss: 0.173665\n",
            "Train Epoch: 2 [24000/40000 (60%)]\tLoss: 0.194988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6b5VGNK6jiJu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Implemente uma rede de classificação de vídeos utilizando convoluções 3D (`nn.Conv3d()`)"
      ]
    },
    {
      "metadata": {
        "id": "Pej2Xck6jiJv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Video3DConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Video3DConvNet, self).__init__() \n",
        "        conv_1 = nn.Conv3d(in_channels=1, out_channels=32, kernel_size=(3,3,2))\n",
        "        pool = nn.MaxPool3d(2)\n",
        "        relu = nn.ReLU()        \n",
        "        conv_2 = nn.Conv3d(in_channels=32, out_channels=64, kernel_size=(3,3,2))\n",
        "        f = Flatten()\n",
        "        fc = nn.Linear(3136, 2)\n",
        "        self.conv = nn.Sequential(*[conv_1, relu, pool, conv_2, relu, pool, f, fc])\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.permute(0,2,1,3,4)\n",
        "        x = self.conv(x)        \n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NHuvaMo3jiJx",
        "colab_type": "code",
        "outputId": "eb75c1d6-5e3d-40f4-f0c2-4c7ffb7ad7bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1288
        }
      },
      "cell_type": "code",
      "source": [
        "model = Video3DConvNet().to(device)\n",
        "print(model)\n",
        "\n",
        "pred = model(torch.zeros(5, 3, 1, 28, 28))\n",
        "print(pred.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video3DConvNet(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv3d(1, 32, kernel_size=(3, 3, 2), stride=(1, 1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv3d(32, 64, kernel_size=(3, 3, 2), stride=(1, 1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Flatten()\n",
            "    (7): Linear(in_features=3136, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "torch.Size([5, 3, 1, 28, 28])\n",
            "torch.Size([5, 1, 3, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-a54c1531e87b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-4d970166ea79>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/pooling.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    207\u001b[0m         return F.max_pool3d(input, self.kernel_size, self.stride,\n\u001b[1;32m    208\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mmax_pool3d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool3d\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \"\"\"\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool3d_with_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (32x1x26x27). Calculated output size: (32x0x13x13). Output size is too small at /pytorch/aten/src/THNN/generic/VolumetricDilatedMaxPooling.c:84"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "RsCS7RjNjiJ0",
        "colab_type": "code",
        "outputId": "a14789b0-1255-4507-fdb8-4091636f6787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 1, 28, 28])\n",
            "Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "feG8CS7IjiJ1",
        "colab_type": "code",
        "outputId": "781fd116-e830-46a2-dc87-5f9aa52bd466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1166
        }
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/40000 (0%)]\tLoss: 0.690310\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-f93f64f9fa19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Final acc: {:.2f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-8215eb87eebf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n* * * Evaluating * * *'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-8215eb87eebf>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, device, train_loader, optimizer, criterion, epoch, log_interval)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-95-167e608740e0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/conv.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 421\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}