{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 1 - RNN no MNIST-[HP].ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "vse27",
      "language": "python",
      "name": "vse27"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bsguedes/machine-learning/blob/master/Aula_1_RNN_no_MNIST_%5BHP%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "nlp6fXSo8coF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yCfiF4lW8coR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Atenção: Rode esta linha apenas se estiver usando o Google Colab"
      ]
    },
    {
      "metadata": {
        "id": "EUM1FxWb8coV",
        "colab_type": "code",
        "outputId": "451006d3-4e84-4e63-a927-5b096beed389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mfastai 0.7.0 has requirement torch<0.4, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wSsnOVcp8cog",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchvision\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eAatgEqx8com",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### O código da célula abaixo contém funções para efetuar a carga dos dados, treinamento teste dos modelos"
      ]
    },
    {
      "metadata": {
        "id": "_TEPkXT58cop",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_loaders(batch_size):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=datasets.MNIST(\n",
        "            root='../data', \n",
        "            train=True, \n",
        "            download=True,\n",
        "            transform=transform,\n",
        "        ),\n",
        "        batch_size=batch_size, \n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        dataset=datasets.MNIST(\n",
        "            root='../data', \n",
        "            train=False, \n",
        "            download=True,\n",
        "            transform=transform,\n",
        "        ),\n",
        "        batch_size=batch_size, \n",
        "        shuffle=True\n",
        "    )\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def train_epoch(\n",
        "        model, \n",
        "        device, \n",
        "        train_loader, \n",
        "        optimizer, \n",
        "        criterion, \n",
        "        epoch, \n",
        "        log_interval\n",
        "    ):\n",
        "    model.train()\n",
        "    history = []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(\n",
        "        model, \n",
        "        device, \n",
        "        criterion, \n",
        "        test_loader\n",
        "    ):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item() # sum up batch loss\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        accuracy))\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def train(\n",
        "        model,\n",
        "        train_loader,\n",
        "        test_loader,\n",
        "        device,\n",
        "        lr,\n",
        "        nb_epochs=3,\n",
        "        log_interval=100,\n",
        "    ):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    for epoch in range(1, nb_epochs + 1):\n",
        "        print('\\n* * * Training * * *')\n",
        "        train_epoch(\n",
        "            model=model, \n",
        "            device=device, \n",
        "            train_loader=train_loader, \n",
        "            optimizer=optimizer, \n",
        "            criterion=criterion, \n",
        "            epoch=epoch, \n",
        "            log_interval=log_interval\n",
        "        )\n",
        "        print('\\n* * * Evaluating * * *')\n",
        "        acc = test(model, device, criterion, test_loader)        \n",
        "    \n",
        "    return acc\n",
        "\n",
        "def check_input(model, device):\n",
        "    dummy_data = torch.zeros(5, 1, 28, 28).to(device)\n",
        "    dummy_pred = model(dummy_data)        \n",
        "    assert dummy_pred.shape == (5, 10), '\\nOutput expected: (batch_size, 10) \\nOutput found   : {}'.format(dummy_pred.shape)\n",
        "    print('Passed')\n",
        "    return dummy_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xq0qpZ1r8cou",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Hyper-parâmetros que você pode definir"
      ]
    },
    {
      "metadata": {
        "id": "2IZ8PKgd8cox",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "device_name = 'cpu'\n",
        "nb_epochs = 3\n",
        "log_interval = 500\n",
        "lr = 1e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q-S_vJEy8co1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(device_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oJcGV_T68co6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conferência dos dados"
      ]
    },
    {
      "metadata": {
        "id": "Xl3-iKCS8co8",
        "colab_type": "code",
        "outputId": "de2e0bef-45e5-4bd2-eef4-fe7bb22138c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = get_loaders(batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FR4gBZwH8cpC",
        "colab_type": "code",
        "outputId": "1648a0a7-b3ac-4d67-c51d-5aa9d6844f4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\n",
        "    'Train size: ', \n",
        "    train_loader.dataset.train_data.shape, \n",
        "    train_loader.dataset.train_labels.shape\n",
        ")\n",
        "print(\n",
        "    'Test size : ', \n",
        "    test_loader.dataset.test_data.shape, \n",
        "    test_loader.dataset.test_labels.shape\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train size: ', torch.Size([60000, 28, 28]), torch.Size([60000]))\n",
            "('Test size : ', torch.Size([10000, 28, 28]), torch.Size([10000]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nqrvgVnu8cpG",
        "colab_type": "code",
        "outputId": "5330740b-55a3-4fd8-bdb7-6c2b7fcf8e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "instance = next(iter(train_loader))\n",
        "print('Instance Example: ', instance[0].shape, instance[1].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Instance Example: ', torch.Size([16, 1, 28, 28]), torch.Size([16]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XnTn7UKp8cpL",
        "colab_type": "code",
        "outputId": "15e8f592-b494-4b49-808a-c520909e3327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 5)\n",
        "for i, ax in enumerate(axs):\n",
        "    ax.imshow(train_loader.dataset.train_data[i], cmap='gray')\n",
        "    ax.set_title(train_loader.dataset.train_labels[i].item())\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABXCAYAAACnZJZlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WmhIMuE48cpO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Seu trabalho começa aqui:"
      ]
    },
    {
      "metadata": {
        "id": "XTO4nu7t8cpP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Implemente aqui sua primeira arquitetura com `nn.LSTM()` \n",
        "\n",
        "Sua LSTM deve ser capaz de classificar as imagens do MNIST processando de forma recorrente as linhas ou colunas. Lembre-se que as imagens do MNIST tem apenas 1 canal, isto é, elas são em escala de cinza (e não RBG!). \n",
        "* Spoiler: LSTM com 32 neurônios, atinge ~96% de acurácia em 3 épocas. "
      ]
    },
    {
      "metadata": {
        "id": "bkK3LZ-e8cpQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DigitsLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DigitsLSTM, self).__init__()\n",
        "        self.input_size = 28\n",
        "        self.hidden_size = 10\n",
        "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(self.hidden_size, 10)\n",
        "\n",
        "    def forward(self, x):   \n",
        "        x = x.squeeze(dim=1)\n",
        "        out, (h, c) = self.lstm(x)\n",
        "        out = out[:,-1,:]\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Xbq-cR_8cpU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 Verifique se a saída do seu modelo está correta"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "gH_xdoZo8cpW",
        "colab_type": "code",
        "outputId": "20e465db-6b5b-4ce2-c3e4-272f06d0160b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = DigitsLSTM().to(device)\n",
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uhhcuqNm8cpb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 Treine seu modelo por uma 1 época\n",
        "Valores de acc esperados por época: \n",
        "1. 93.5%\n",
        "2. 94.5%\n",
        "3. 96.8%"
      ]
    },
    {
      "metadata": {
        "id": "r9cxMWWb8cpb",
        "colab_type": "code",
        "outputId": "911e6c74-0ac3-4dba-e626-2dabb0ab828d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.289378\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.413532\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.103156\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.072085\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.649132\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.092195\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.041524\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.622199\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0459, Accuracy: 7654/10000 (76.54%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.828224\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.381806\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.812134\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.340530\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.583479\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.277976\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.212978\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.413995\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0289, Accuracy: 8618/10000 (86.18%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.784454\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.218850\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.997476\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.194735\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.366436\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.127715\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.613549\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.460081\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0222, Accuracy: 8945/10000 (89.45%)\n",
            "\n",
            "Final acc: 89.45%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cxHln6_B8cpe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Implemente aqui sua arquitetura com `nn.LSTMCell()` \n",
        "\n",
        "Semelhante à arquitetura anterior, sua LSTM deve processar imagens do MNIST iterando sobre as linhas ou as colunas das imagens. A diferença é que agora você deve implementar utilizando uma nn.LSTMCell(). Para isso, você deverá utilizar um laço de repetição `for`."
      ]
    },
    {
      "metadata": {
        "id": "bJuCWM708cpe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DigitsCellLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DigitsCellLSTM, self).__init__()\n",
        "        self.rnn = nn.LSTMCell(28, 32)\n",
        "        self.fc = nn.Linear(32, 10)\n",
        "        \n",
        "    def forward(self, x):        \n",
        "        x = x.squeeze(dim=1)     \n",
        "        batch, time_steps, features = x.shape\n",
        "        hidden_activations = torch.zeros(batch, 32)\n",
        "        cell_activations = torch.zeros(batch, 32)\n",
        "        for time_step in range(time_steps):\n",
        "          xt = x[:,time_step,:]\n",
        "          (hidden_activations, cell_activations) = self.rnn(xt, (hidden_activations, cell_activations))\n",
        "        x = self.fc(hidden_activations)\n",
        "        return x\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "hUdXhqD18cpg",
        "colab_type": "code",
        "outputId": "7d9b0cb5-094f-4b80-800d-3f6d8e63e052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "model = DigitsCellLSTM()\n",
        "print(model)\n",
        "\n",
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DigitsCellLSTM(\n",
            "  (rnn): LSTMCell(28, 32)\n",
            "  (fc): Linear(in_features=32, out_features=10, bias=True)\n",
            ")\n",
            "Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4USOZLx28cpi",
        "colab_type": "code",
        "outputId": "08b9bb58-e563-4f90-aedd-accedb38b514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.234715\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.496461\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.491291\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.161160\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.512977\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.100089\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.488399\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.106541\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0139, Accuracy: 9309/10000 (93.09%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.050692\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.049443\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.066417\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.109674\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.046622\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.437856\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.280260\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.250621\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0090, Accuracy: 9570/10000 (95.70%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.173099\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.060937\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.114760\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.075993\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.044770\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.102727\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.007960\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.039678\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0077, Accuracy: 9627/10000 (96.27%)\n",
            "\n",
            "Final acc: 96.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QP0jehF18cpk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Fique à vontade para testar outras variações das suas arquiteturas para conseguir resultados melhores\n",
        "\n",
        "Ideias: \n",
        "* Aumente o número de camadas na LSTM\n",
        "* Teste GRU\n",
        "* Teste arquiteturas bidirecionais"
      ]
    },
    {
      "metadata": {
        "id": "-_kWSJe48cpk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class YourLSTM(nn.Module):\n",
        "    def __init__():\n",
        "        super(YourLSTM, self).__init__()            \n",
        "\n",
        "    def forward(self, x):        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}